import json
import uuid
import time
import random
from typing import List

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles

from config import logger, MODEL_MAPPING, last_account_index, CHAT_ID_TO_ACCOUNT, SESSION_CACHE, IMAGE_SAVE_DIR
from models import Message, ChatRequest, ChatImage
from auth import Account, accounts
from chat import parse_last_message, build_full_context_text, create_chunk, stream_chat_generator, get_conversation_key
from session import create_google_session, list_session_files, save_generated_image, upload_context_file

def estimate_tokens(text: str) -> int:
    """ç®€å•ä¼°ç®—tokenæ•°ï¼Œå¤§çº¦4ä¸ªå­—ç¬¦1ä¸ªtoken"""
    return len(text) // 4

def calculate_usage(prompt_text: str, completion_text: str) -> dict:
    """è®¡ç®—tokenä½¿ç”¨æƒ…å†µ"""
    prompt_tokens = estimate_tokens(prompt_text)
    completion_tokens = estimate_tokens(completion_text)
    return {
        "prompt_tokens": prompt_tokens,
        "completion_tokens": completion_tokens,
        "total_tokens": prompt_tokens + completion_tokens
    }

# ---------- OpenAI å…¼å®¹æ¥å£ ----------
app = FastAPI(title="Gemini-Business OpenAI Gateway")

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/images", StaticFiles(directory=str(IMAGE_SAVE_DIR)), name="images")

@app.get("/v1/models")
async def list_models():
    data = []
    now = int(time.time())
    for m in MODEL_MAPPING.keys():
        data.append({
            "id": m,
            "object": "model",
            "created": now,
            "owned_by": "google",
            "permission": []
        })
    return {"object": "list", "data": data}

@app.get("/v1/chat/completions/{chat_id}/account")
async def get_account(chat_id: str):
    account = CHAT_ID_TO_ACCOUNT.get(chat_id)
    if account:
        return {"account": account}
    else:
        raise HTTPException(status_code=404, detail="Chat ID not found")

@app.post("/v1/chat/completions")
async def chat(req: ChatRequest):
    # 1. æ¨¡å‹æ ¡éªŒ
    if req.model not in MODEL_MAPPING:
        raise HTTPException(status_code=404, detail=f"Model '{req.model}' not found.")

    # 2. è·å–å¯¹è¯æŒ‡çº¹
    conv_key = get_conversation_key([msg.dict() for msg in req.messages])
    
    # 3. æ£€æŸ¥ Session ç¼“å­˜
    cached_session = SESSION_CACHE.get(conv_key)
    google_session = None
    account = None
    
    if cached_session:
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ (5åˆ†é’Ÿ)
        if time.time() - cached_session["updated_at"] < 300:
            google_session = cached_session["session_id"]
            account_name = cached_session["account"]
            account = next((a for a in accounts if a.name == account_name), None)
            if account:
                logger.info(f"ğŸ”„ ä½¿ç”¨ç¼“å­˜ Session: {google_session} è´¦æˆ·: {account.name}")
    
    # 4. å¦‚æœæ²¡æœ‰ç¼“å­˜æˆ–è¿‡æœŸï¼Œé€‰æ‹©è´¦æˆ·å¹¶åˆ›å»ºæ–° Session
    if not google_session or not account:
        # é€‰æ‹©è´¦æˆ· (è´Ÿè½½å‡è¡¡ - è½®è¯¢)
        global last_account_index
        last_account_index = (last_account_index + 1) % len(accounts)
        account = accounts[last_account_index]
        logger.info(f"ğŸ†• å¼€å¯æ–°å¯¹è¯ [{req.model}] ä½¿ç”¨è´¦æˆ·: {account.name}")
        
        # åˆ›å»ºæ–° Session
        google_session = await create_google_session(account)
        
        # æ›´æ–°ç¼“å­˜
        SESSION_CACHE[conv_key] = {
            "session_id": google_session,
            "updated_at": time.time(),
            "account": account.name
        }

    # 5. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = await parse_last_message(req.messages)
    
    # æ–°å¯¹è¯ä½¿ç”¨å…¨é‡æ–‡æœ¬ä¸Šä¸‹æ–‡ (å›¾ç‰‡åªä¼ å½“å‰çš„)
    text_to_send = build_full_context_text(req.messages)

    chat_id = f"chatcmpl-{uuid.uuid4()}"
    created_time = int(time.time())

    # å°è£…ç”Ÿæˆå™¨ (å«å›¾ç‰‡ä¸Šä¼ å’Œé‡è¯•é€»è¾‘)
    async def response_wrapper(session: str, acc: Account):
        # å›¾ç‰‡ ID åˆ—è¡¨ (æ¯æ¬¡ Session å˜åŒ–éƒ½éœ€è¦é‡æ–°ä¸Šä¼ ï¼Œå› ä¸º fileId ç»‘å®šåœ¨ Session ä¸Š)
        file_ids = []
        
        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆä¸Šä¼ 
        if current_images:
            for img in current_images:
                fid = await upload_context_file(acc, session, img["mime"], img["data"])
                file_ids.append(fid)

        # å‘èµ·å¯¹è¯
        async for chunk in stream_chat_generator(
            acc,
            session, 
            text_to_send, 
            file_ids, 
            req.model, 
            chat_id, 
            created_time, 
            req.stream
        ):
            yield chunk

    if req.stream:
        return StreamingResponse(response_wrapper(google_session, account), media_type="text/event-stream")
    
    full_content = ""
    async for chunk_str in response_wrapper(google_session, account):
        if chunk_str.startswith("data: [DONE]"): break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta: full_content += delta["content"]
            except: pass

    # æ£€æŸ¥æ˜¯å¦æœ‰AIç”Ÿæˆçš„å›¾ç‰‡
    ai_files = await list_session_files(account, google_session)
    generated_images = []
    if ai_files:
        for i, file_meta in enumerate(ai_files):
            try:
                chat_image = await save_generated_image(
                    account, google_session, file_meta["fileId"], 
                    file_meta.get("fileName"), file_meta.get("mimeType", "image/png"), 
                    chat_id, i+1
                )
                generated_images.append(chat_image)
            except Exception as e:
                logger.error(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {e}")

    # å¦‚æœæœ‰ç”Ÿæˆçš„å›¾ç‰‡ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå›¾ç‰‡çš„URLï¼Œå¦åˆ™è¿”å›æ–‡æœ¬
    if generated_images:
        content = generated_images[0].url
    else:
        content = full_content

    CHAT_ID_TO_ACCOUNT[chat_id] = account.name
    
    # è®¡ç®—usage
    usage = calculate_usage(text_to_send, content)
    
    return {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [{"index": 0, "message": {"role": "assistant", "content": content}, "finish_reason": "stop"}],
        "usage": usage
    }